# First-Small-ETL

Un projet de pipeline ETL (Extract, Transform, Load) minimaliste conÃ§u Ã  des fins d'apprentissage. Ce pipeline extrait des donnÃ©es d'un fichier CSV contenant des informations sur des voitures, les transforme, puis les charge dans une base de donnÃ©es PostgreSQL.

---

## ğŸš€ FonctionnalitÃ©s principales
- **Extraction** : Lecture des donnÃ©es Ã  partir d'un fichier CSV (`cars.csv`) dans un DataFrame pandas.
- **Transformation** : Nettoyage et renommage des colonnes, remplacement de valeurs et prÃ©paration des donnÃ©es pour le chargement.
- **Chargement** : Insertion des donnÃ©es transformÃ©es dans une table PostgreSQL.
- **ModularitÃ©** : Scripts sÃ©parÃ©s pour chaque Ã©tape (Extraction, Transformation, Chargement) et un script principal pour orchestrer l'ensemble du pipeline.

---

## ğŸ› ï¸ PrÃ©requis
Pour exÃ©cuter ce pipeline, vous aurez besoin de :
- **PostgreSQL** installÃ© et en cours d'exÃ©cution.
- **Python** (version 3.x recommandÃ©e).
- **Pip** pour gÃ©rer les paquets Python.
- Un fichier `.env` contenant les variables de connexion suivantes pour PostgreSQL :
  ```
  DB_USER=<votre-utilisateur>
  DB_PASSWORD=<votre-mot-de-passe>
  DB_HOST=<votre-hÃ´te>
  DB_PORT=<votre-port>
  DB_NAME=<votre-nom-de-base-de-donnÃ©es>
  ```
- Les bibliothÃ¨ques Python listÃ©es dans `requirements.txt` (par exemple, `pandas`, `sqlalchemy`, `python-dotenv`).

---

## ğŸ“¦ Installation

1. **Cloner le dÃ©pÃ´t** :
   ```bash
   git clone https://github.com/Mosdef00/first-small-etl.git
   cd first-small-etl
   ```

2. **Installer les dÃ©pendances** :
   ```bash
   pip install -r requirements.txt
   ```

3. **Configurer PostgreSQL** :
   - CrÃ©ez une base de donnÃ©es avec le nom spÃ©cifiÃ© dans votre fichier `.env`.
   - Assurez-vous que les dÃ©tails de connexion dans le fichier `.env` correspondent.

4. **Ajouter les donnÃ©es d'entrÃ©e** :
   - VÃ©rifiez que le fichier `data/input/cars.csv` existe et respecte la structure prÃ©vue.

---

## ğŸš€ Utilisation

1. **ExÃ©cuter le pipeline ETL** :
   Lancez le script principal pour exÃ©cuter toutes les Ã©tapes (Extraction, Transformation, Chargement) :
   ```bash
   python src/run.py
   ```

2. **ExÃ©cuter les Ã©tapes individuellement** :
   - Extraction :
     ```bash
     python src/extract.py
     ```
   - Transformation :
     ```bash
     python src/transform.py
     ```
   - Chargement :
     ```bash
     python src/load.py
     ```

---

## ğŸ“‚ Structure du projet

```
first-small-etl/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ input/
â”‚       â””â”€â”€ cars.csv          # Fichier de donnÃ©es d'entrÃ©e
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb     # Notebook Jupyter pour l'exploration des donnÃ©es
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract.py            # Gestion de l'extraction des donnÃ©es
â”‚   â”œâ”€â”€ transform.py          # Gestion de la transformation des donnÃ©es
â”‚   â”œâ”€â”€ load.py               # Gestion du chargement des donnÃ©es
â”‚   â””â”€â”€ run.py                # Orchestration du processus ETL
â”œâ”€â”€ requirements.txt          # DÃ©pendances des paquets Python
â””â”€â”€ README.md                 # Documentation du projet
```

---

## ğŸ¾ AmÃ©liorations futures
- **IntÃ©gration Ã  la base de donnÃ©es** : Ajouter des requÃªtes SQL directement dans les scripts du pipeline ETL pour simplifier le workflow, remplaÃ§ant l'exÃ©cution manuelle dans `pgcli`.
- **Tests** : ImplÃ©menter des tests unitaires et d'intÃ©gration pour chaque Ã©tape ETL afin de garantir la cohÃ©rence des donnÃ©es et la fiabilitÃ© du pipeline.
- **Versionnement** : Introduire un systÃ¨me de versionnement pour le pipeline, permettant un meilleur suivi des modifications et des amÃ©liorations au fil du temps.
- **Gestion des erreurs** : Ajouter une gestion exhaustive des erreurs et un systÃ¨me de journalisation pour traiter les cas particuliers et les Ã©checs imprÃ©vus.
- **Ã‰volutivitÃ©** : Optimiser la performance et l'Ã©volutivitÃ© pour les ensembles de donnÃ©es plus volumineux.
- **Documentation** : Ã‰tendre le README avec des exemples de transformations de donnÃ©es et de requÃªtes SQL pour plus de clartÃ©.

---

## ğŸ“ Licence
Ce projet est Ã  des fins Ã©ducatives et est sous licence MIT.

